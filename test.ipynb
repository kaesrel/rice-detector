{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import argparse\n",
    "import os\n",
    "import glob\n",
    "import yolo_detector as yolo\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/prom/work/other/opencv_study/rice_dnn\"\n",
    "weights = f\"{path}/backup/yolov4-rice-split-dnsty_best.weights\"\n",
    "config = f\"{path}/cfg/yolov4-rice-split-dnsty.cfg\"\n",
    "classes = f\"{path}/obj.names\"\n",
    "images_path = f\"{path}/dense_and_sparse_label\"\n",
    "confidence = 0.4\n",
    "nms = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = yolo.YoloDetector(weights, config, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/prom/work/other/opencv_study/rice_dnn/dense_and_sparse_label/IMG_20230115_164110.jpg',\n",
       " '/home/prom/work/other/opencv_study/rice_dnn/dense_and_sparse_label/LINE_ALBUM_rice_100_dense_๒๓๐๒๑๖_0.jpg',\n",
       " '/home/prom/work/other/opencv_study/rice_dnn/dense_and_sparse_label/LINE_ALBUM_rice_100_sparse_๒๓๐๒๑๖_23.jpg',\n",
       " '/home/prom/work/other/opencv_study/rice_dnn/dense_and_sparse_label/LINE_ALBUM_rice_100_dense_๒๓๐๒๑๖_2.jpg']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f\"{path}/test.txt\"\n",
    "test_images = open(file=f\"{path}/test.txt\").readlines()\n",
    "test_files = [f\"{path}/{line[:-1]}\" for line in test_images]\n",
    "test_files[:4]\n",
    "# !cat \"{path}/test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = []\n",
    "exts = ['*.jpg', '*.png']\n",
    "all_files = [f for ext in exts for f in glob.glob(os.path.join(images_path, ext))]\n",
    "files = all_files\n",
    "# files = test_files\n",
    "\n",
    "\n",
    "predict = []\n",
    "actual = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for file in files:\n",
    "    image = cv2.imread(file)\n",
    "\n",
    "    # labels = detector.detect_and_label(image, args.confidence, args.nms)\n",
    "    classes, scores, boxes = detector.detect(image, confidence, nms)\n",
    "    labels = detector.label(image)\n",
    "    predict.append(classes[0])\n",
    "\n",
    "    # print(file)\n",
    "    path = os.path.splitext(file)\n",
    "    if os.path.isfile(path[0]+'.txt'):\n",
    "        txtfile = open(path[0]+'.txt','r')\n",
    "        lines = txtfile.readlines()\n",
    "        for line in lines:\n",
    "            classid = int(line.split(' ')[0])\n",
    "            if len(classes) <=0 or classid != classes[0]:\n",
    "                is_match = False\n",
    "            actual.append(classid)\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[57  2  0  0  0  0  0  0]\n",
      " [ 1 56  1  0  0  0  0  0]\n",
      " [ 0  1 58  0  0  0  0  0]\n",
      " [ 0  0  0 58  0  0  0  0]\n",
      " [ 0  0  0  0  4  0  0  0]\n",
      " [ 0  0  0  0  0 28  2  0]\n",
      " [ 0  0  0  0  0  0 27  0]\n",
      " [ 0  0  0  0  0  0  0 30]]\n"
     ]
    }
   ],
   "source": [
    "# actual\n",
    "print(metrics.confusion_matrix(actual,predict))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97        59\n",
      "           1       0.95      0.97      0.96        58\n",
      "           2       0.98      0.98      0.98        59\n",
      "           3       1.00      1.00      1.00        58\n",
      "           4       1.00      1.00      1.00         4\n",
      "           5       1.00      0.93      0.97        30\n",
      "           6       0.93      1.00      0.96        27\n",
      "           7       1.00      1.00      1.00        30\n",
      "\n",
      "    accuracy                           0.98       325\n",
      "   macro avg       0.98      0.98      0.98       325\n",
      "weighted avg       0.98      0.98      0.98       325\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(metrics.classification_report(actual, predict, target_names=detector.class_name, labels=detector.class_name))\n",
    "print(metrics.classification_report(actual, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/prom/work/other/opencv_study/rice_dnn/dense_and_sparse_label/LINE_ALBUM_rice_5_sparse_๒๓๐๒๑๖_27.jpg\n",
      "Actual:  ['rice_5_sparse']  Match:  True\n",
      "Predict:  ['rice_5_sparse: 0.9989']\n"
     ]
    }
   ],
   "source": [
    "!python3 rice_detector.py -c=/home/prom/work/other/opencv_study/rice_dnn/cfg/yolov4-rice-split-dnsty.cfg -w=/home/prom/work/other/opencv_study/rice_dnn/backup/yolov4-rice-split-dnsty_best.weights -cl=/home/prom/work/other/opencv_study/rice_dnn/obj.names -p=/home/prom/work/other/opencv_study/rice_dnn/dense_and_sparse_label/LINE_ALBUM_rice_5_sparse_๒๓๐๒๑๖_27.jpg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
